{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rimuru102/Card_classification_CNN/blob/main/StratAI_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # Task Notebook\n",
        "  We know how desperate u guys have been to do this but now hold on to get started with some cool Math-driven ML stuff\n",
        "  ## Instructions:\n",
        "  1. Download a local copy of this notebook on your system/drive. You can edit this copy either on google colab or VScode.\n",
        "  2. Use AI to learn AI! The best resource for this task is [Perplexity](https://www.perplexity.ai/)"
      ],
      "metadata": {
        "id": "eiHbtZsAQRof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Silence before the storm\n",
        "Do you guys remember the expressions for Gradient Descent? \\\\\n",
        "$$w_i=w_i-α\\frac{\\partial J}{\\partial w_i}$$ and\n",
        "$$b=b-α\\frac{\\partial J}{\\partial b}$$\n",
        "\n",
        "Using the above, get the equations of Gradient Descent for Linear and Logisitic Regression"
      ],
      "metadata": {
        "id": "Wtou_eOOaskY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: The Storm\n",
        "Train a regression model to learn the following functions\n",
        "1. $f(x) = 5x + 3$\n",
        "2. $f(x) = 2x^2 + 3x + 12$\n",
        "3. $f(x) = \\sin 5x + \\cos 3x$\n",
        "4. $f(x) = e^{x^2/2}$\n",
        "\n",
        "\n",
        "\\\\\n",
        "This task is to be done in the following steps \\\\\n",
        "A. Generating training data: \\\\\n",
        "A1 Generate data-sets with randomly sampled values of x and corresponding values of y \\\\\n",
        "A2 Now create another noisy data set where $(x,y)$ pairs are such that $y = f(x)+\\epsilon$ where $\\epsilon$ is gaussian noise with 0 mean and some fixed small variance of your choice.\n",
        "\n",
        "B. Setting up your model: \\\\\n",
        "B1 Create a simple linear model fitting a polynomial function for the above generated datasets. More concretely, try to learn the function $$\\Sigma_{i=0}^{n} w_ix^i$$ with n of your choice (will determine model complexity). Call this Model NN_1 \\\\\n",
        "\n",
        "\\\\\n",
        "B2 Now create Feed Forward Neural Network with 2 and 3 and call them NN_2 and NN_3. Create variants of these models by choosing the activation to be (i) linear (ii) ReLU (iii) Softmax\n",
        "\n",
        "Feel free to play around with number of neurons in every layer, but make sure to start with a small network. \\\\\n",
        "\n",
        "C. Training your model \\\\\n",
        "C1 Use the following optimisation algorithms: (i) gradient descent, (ii) Adam (iii) Momentum to update the weights during training. \\\\\n",
        "C2 Tweak hyperparameters to figure out the best accuracy (part D)\n",
        "C3 Use (i) Mean squared loss and (ii) Mean absolute error as your loss functions.\n",
        "\n",
        "D. Analysing Performance \\\\\n",
        "Now that you have built your sweet little models, its time to test them! Repeat A1 to generate test datasets. These datasets will be smaller than your training sets. Use your loss functions as the performance metric.\n",
        "\n",
        "E. Plot graphs of the loss function during the model training for after every 50-100 iterations and visualise model learning.\n",
        "\n",
        "You should document your performance/errors on the training/test data along with plots on different variants of the \\\\\n",
        "(i) data generation \\\\\n",
        "(ii) model architecture \\\\\n",
        "(iii) optimisation algorithm \\\\\n",
        "\n",
        "For a particular choice of Loss function.\n",
        "\n",
        "Analyse how these factors affect model accuracy and performance. Performance refers to how quickly (number of iterations) the model gives training error less than a given threshold"
      ],
      "metadata": {
        "id": "4U8DWSMARqr9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFKzDiDPsJhk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}